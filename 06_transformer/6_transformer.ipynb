{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d6afab19e56b7dab3da794832962c35",
     "grade": false,
     "grade_id": "cell-f5e46023398b0aab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 4\n",
    "<br>\n",
    "<b>Deadline:</b> April 13, 2020 (Monday). 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 6. Neural machine translation with transformers.\n",
    "\n",
    "The goal of this exerscise is to get familiar with a transformer model, which was introduced in the paper [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "We base our code on the implementation in the [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) blog post. We recommend you to go through that blog post before doing this exercise.\n",
    "\n",
    "Note: We provide module `transformer.py` which contains some useful modules from the annotated transformer code. We recommend to use those modules when we state so in the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformer as tr\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbbca8fe9cf0cb1cb20dd200e23cfcb0",
     "grade": false,
     "grade_id": "cell-44cf6f3242607cde",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7fd231dc4a3319981678549c38c5d02",
     "grade": false,
     "grade_id": "cell-1f1e529682d7ce6d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "We use the same translation dataset as in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f04ad11eea93bfc2b77e1b5e7b74f93",
     "grade": false,
     "grade_id": "cell-94d57799bcd1786b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence:\n",
      " as word indexes:  tensor([ 24, 246,  25, 247,  96,  35, 681,   5,   1])\n",
      " as words:  il n est pas du tout satisfait . EOS\n",
      "Target sentence:\n",
      " as word indexes:  tensor([ 14, 544, 545, 225, 159, 156,   4,   1])\n",
      " as words:  he isn t happy at all . EOS\n"
     ]
    }
   ],
   "source": [
    "# Translation data\n",
    "from data import TranslationDataset, SOS_token, EOS_token, MAX_LENGTH\n",
    "trainset = TranslationDataset(data_dir, train=True)\n",
    "\n",
    "src_seq, tgt_seq = trainset[np.random.choice(len(trainset))]\n",
    "print('Source sentence:')\n",
    "print(' as word indexes: ', src_seq)\n",
    "print(' as words: ', ' '.join(trainset.input_lang.index2word[i.item()] for i in src_seq))\n",
    "\n",
    "print('Target sentence:')\n",
    "print(' as word indexes: ', tgt_seq)\n",
    "print(' as words: ', ' '.join(trainset.output_lang.index2word[i.item()] for i in tgt_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e4762e32894ed6afcd3b5af8d7777ee",
     "grade": false,
     "grade_id": "cell-86482ed71ea81ed3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Custom DataLoader\n",
    "\n",
    "Next we prepare a custom data loader which puts sequences of varying lengths in one tensor. We do so by using a custom `collate_fn` as explained [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "Our collate function combines source sequences in one tensor `src_seqs` with extra values (at the end) filled with `PADDING_VALUE=0`. To tell the transformer which elements are padded, we also need to compute the mask `src_mask`.\n",
    "\n",
    "The function also combines target sequences in one tensor `tgt_seqs` but it does it a bit differently:\n",
    "* The resulting tensor is of shape `(max_tgt_seq_length+1, batch_size)`, where `max_tgt_seq_length` is the length of the longest target sequence in the mini-batch.\n",
    "* The first element of each sequence in the resulting tensor is `SOS_token`.\n",
    "* The remaining elements are filled similarly to the source sequences with extra values (at the end) filled with `PADDING_VALUE=0`.\n",
    "\n",
    "We will use tensor `tgt_seqs[:-1]` as inputs of the transformer decoder and `tgt_seqs[1:]` as the targets for the model (decoder) outputs. The `SOS_token` is needed to predict the first word in the output sequence in the corresponding (first) location of the decoder output.\n",
    "\n",
    "Your task is to implement this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51df20f688b9b190af9bb01687b5603f",
     "grade": false,
     "grade_id": "collate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PADDING_VALUE = 0\n",
    "\n",
    "def collate(list_of_samples):\n",
    "    \"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "    Args:\n",
    "      list_of_samples is a list of tuples (src_seq, tgt_seq):\n",
    "          src_seq is of shape (src_seq_length)\n",
    "          tgt_seq is of shape (tgt_seq_length)\n",
    "\n",
    "    Returns:\n",
    "      src_seqs of shape (max_src_seq_length, batch_size): Tensor of padded source sequences.\n",
    "      src_mask of shape (max_src_seq_length, batch_size): Boolean tensor showing which elements of the\n",
    "          src_seqs tensor should be ignored in computations (filled with PADDING_VALUE).\n",
    "      tgt_seqs of shape (max_tgt_seq_length+1, batch_size): Tensor of padded target sequences.\n",
    "    \"\"\"\n",
    "    len_src,len_tgt=[],[]\n",
    "    src_seqs, tgt_seqs = [],[]\n",
    "    for a in list_of_samples:\n",
    "        len_src.append(len(a[0]))\n",
    "        src_seqs.append(a[0])\n",
    "        len_tgt.append(len(a[1]))\n",
    "        tgt_seqs.append(a[1])\n",
    "    src_padded, src_mask, tgt_padded = [],[], []\n",
    "    for seq in src_seqs:\n",
    "        src_padded.append(list(torch.cat((seq, torch.zeros(max(len_src) - list(seq.shape)[0], dtype=seq.dtype, device=seq.device)), dim=0)))\n",
    "        src_mask.append(list(torch.cat((torch.zeros(len(seq), dtype=torch.bool,device=device), torch.ones(max(len_src) - list(seq.shape)[0], dtype=torch.bool, device=device)), dim=0)))\n",
    "    for seq in tgt_seqs:\n",
    "        tgt_padded.append(list(torch.cat((torch.tensor([SOS_token], dtype=seq.dtype, device=device), seq, torch.zeros(max(len_tgt) - list(seq.shape)[0], dtype=seq.dtype, device=seq.device)), dim=0)))\n",
    "\n",
    "    src_padded = torch.tensor(np.array(src_padded).T).to(device)\n",
    "    src_mask = torch.tensor(np.array(src_mask).T).to(device)\n",
    "    tgt_padded = torch.tensor(np.array(tgt_padded).T).to(device)\n",
    "    return src_padded, src_mask, tgt_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ce1cbec7ff20d420fc4a68362c5e481",
     "grade": false,
     "grade_id": "cell-a99b4cfa1fc559f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_collate_shapes():\n",
    "    pairs = [\n",
    "        (torch.LongTensor([2, EOS_token]), torch.LongTensor([3, 4, EOS_token])),\n",
    "        (torch.LongTensor([6, 7, EOS_token]), torch.LongTensor([9, EOS_token])),\n",
    "    ]\n",
    "    src_seqs, src_mask, tgt_seqs = collate(pairs)\n",
    "    assert src_seqs.dtype == torch.long, f\"Wrong src_seqs.dtype: {src_seqs.dtype}\"\n",
    "    assert src_seqs.shape == torch.Size([3, 2]), f\"Wrong src_seqs.shape: {src_seqs.shape}\"\n",
    "\n",
    "    assert tgt_seqs.dtype == torch.long, f\"Wrong tgt_seqs.dtype: {tgt_seqs.dtype}\"\n",
    "    assert tgt_seqs.shape == torch.Size([4, 2]), f\"Wrong tgt_seqs.shape: {tgt_seqs.shape}\"\n",
    "    assert (tgt_seqs[0] == torch.empty(2, dtype=torch.long).fill_(SOS_token)).all(), \"Target sequences should start with SOS_token.\"\n",
    "    \n",
    "    assert src_mask.dtype == torch.bool, f\"Wrong src_mask.dtype: {src_mask.dtype}\"\n",
    "    assert src_mask.shape == src_seqs.shape, f\"Wrong src_mask.shape: {src_mask.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_collate_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80199eca201cfa31cfd5c7d84b9f8249",
     "grade": true,
     "grade_id": "test_collate",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f103d72cfd56ec7f6e42872740b6f395",
     "grade": false,
     "grade_id": "cell-e0a6bbaf21ae2a36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 64 sequences at the same time (batch_size=64)\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6627cb26c83634c853b5749710275900",
     "grade": false,
     "grade_id": "cell-3f6dfc8dc7015270",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99f11a8ddd6159a69ec2c3780fe2c776",
     "grade": false,
     "grade_id": "cell-63be98428fcdc0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Encoder block\n",
    "\n",
    "<img src=\"encoder_block.png\" width=150 style=\"float: right;\">\n",
    "\n",
    "We first implement one block of the transformer encoder (see the figure on the right).\n",
    "* We recommend you to use layers available in PyTorch:\n",
    "  * [nn.LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) to implement the `Norm` layer in the figure\n",
    "  * [nn.Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) to implement dropout\n",
    "  * [nn.MultiheadAttention](https://pytorch.org/docs/stable/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention) to implement `Multi-Head Attention`.\n",
    "\n",
    "* `Feedforward` is simply an MLP processing each position (each element of the source sequence) independently. The exact implementation of the MLP is not tested in this notebook. We used an MLP with:\n",
    "  * one hidden layer with `n_hidden` neurons\n",
    "  * a dropout and ReLU activation after the hidden layer\n",
    "  * an output layer with `n_features` outputs.\n",
    "\n",
    "* We used dropout in both skip connections of the encoder block.\n",
    "* In contrast to the [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) code, we applied normalization after the skip connection (like it is shown on the figure).\n",
    "\n",
    "**We recommend you to test that the padded values of the input sequence do not affect the outputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a568031cc712ea463a7a65978dbb696",
     "grade": false,
     "grade_id": "EncoderBlock",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_features: Number of input and output features.\n",
    "          n_heads: Number of attention heads in the Multi-Head Attention.\n",
    "          n_hidden: Number of hidden units in the Feedforward (MLP) block.\n",
    "          dropout: Dropout rate after the first layer of the MLP and the two skip connections.\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.multiheadAttention1 = nn.MultiheadAttention(n_features, n_heads)\n",
    "        self.normlayer1 = nn.LayerNorm(n_features)\n",
    "        self.normlayer2 = nn.LayerNorm(n_features)\n",
    "        self.mlp1 = nn.Sequential(nn.Linear(n_features, n_hidden), nn.Dropout(dropout),\n",
    "                                    nn.ReLU(), torch.nn.Linear(n_hidden,n_features))\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (max_seq_length, batch_size, n_features): Input sequences.\n",
    "          mask of shape (batch_size, max_seq_length): Boolean tensor indicating which elements of the input\n",
    "              sequences should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Encoded input sequence.\n",
    "\n",
    "        Note: All intermediate signals should be of shape (max_seq_length, batch_size, n_features).\n",
    "        \"\"\"\n",
    "        y, _ = self.multiheadAttention1(query=x, key=x, value=x, key_padding_mask=mask)\n",
    "        x = self.normlayer1(self.drop1(y) + x)\n",
    "        x = self.normlayer2(x + self.drop2(self.mlp1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2c3555eb8c14301d30061b3d64149fe",
     "grade": false,
     "grade_id": "cell-67f5cb6fdfecf7d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_EncoderBlock_shapes():\n",
    "    encoder_block = EncoderBlock(n_features=16, n_heads=4, n_hidden=64)\n",
    "\n",
    "    x = torch.tensor([\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 0],\n",
    "        [6, 0],\n",
    "    ]).float().view(4, 2, 1).repeat(1, 1, 16)  # (max_seq_length, batch_size, n_features)\n",
    "\n",
    "    mask = torch.tensor([\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "    ], dtype=torch.bool).T  # (batch_size, max_seq_length)\n",
    "    outputs = encoder_block(x, mask)\n",
    "    assert outputs.shape == torch.Size([4, 2, 16]), f\"Wrong outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_EncoderBlock_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87d80ba7f699f09aedf9c4a27d45c34",
     "grade": true,
     "grade_id": "test_EncoderBlock",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests EncoderBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b121062b3d9db25b2cf16db2bc28af9",
     "grade": false,
     "grade_id": "cell-e2776b50381263dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"encoder.png\" width=200 style=\"float: right;\">\n",
    "\n",
    "## Encoder\n",
    "\n",
    "The encoder is a stack of the following blocks:\n",
    "* Embedding of words (please use [nn.Embedding](https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding))\n",
    "* Positional encoding (please use `tr.PositionalEncoding` from the attached module)\n",
    "* `n_blocks` of the `EncoderBlock` modules.\n",
    "\n",
    "Notes:\n",
    "* Provided implementation of `tr.PositionalEncoding` is the same as in [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) blog post. See the blog post for more detail.\n",
    "* Our longest sequences have length `MAX_LENGTH`, this is the value that you can use when you specify `PositionalEncoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0036f01e993194d6a37f507e49ff7099",
     "grade": false,
     "grade_id": "Encoder",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, n_blocks, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          src_vocab_size: Number of words in the source vocabulary.\n",
    "          n_blocks: Number of EncoderBlock blocks.\n",
    "          n_features: Number of features to be used for word embedding and further in all layers of the encoder.\n",
    "          n_heads: Number of attention heads inside the EncoderBlock.\n",
    "          n_hidden: Number of hidden units in the Feedforward block of EncoderBlock.\n",
    "          dropout: Dropout level used in EncoderBlock.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed1 = nn.Embedding(src_vocab_size, n_features)\n",
    "        self.pos_embed = tr.PositionalEncoding(n_features, max_len=MAX_LENGTH)\n",
    "        self.encoder_blks = nn.Sequential(*[EncoderBlock(n_features, n_heads, n_hidden, dropout) for _ in range(n_blocks)])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (max_seq_length, batch_size): LongTensor with the input sequences.\n",
    "          mask of shape (batch_size, max_seq_length): BoolTensor indicating which elements should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Encoded input sequence.\n",
    "\n",
    "        Note: All intermediate signals should be of shape (max_seq_length, batch_size, n_features).\n",
    "        \"\"\"\n",
    "        emb = self.embed1(x)\n",
    "        pos = self.pos_embed(emb)\n",
    "        inp = emb + pos \n",
    "        for layer in self.encoder_blks:\n",
    "            inp = layer(inp,mask)\n",
    "        return inp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a019378519acf7cc11881562abeca5e1",
     "grade": false,
     "grade_id": "cell-01134ebab1f5117e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Encoder_shapes():\n",
    "    encoder = Encoder(src_vocab_size=10, n_blocks=1, n_features=16, n_heads=4, n_hidden=64)\n",
    "\n",
    "    x = torch.tensor([\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 0],\n",
    "        [6, 0],\n",
    "    ]).view(4, 2)  # (max_seq_length, batch_size)\n",
    "\n",
    "    mask = torch.tensor([\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "    ], dtype=torch.bool).T  # (batch_size, max_seq_length)\n",
    "    outputs = encoder(x, mask)\n",
    "    assert outputs.shape == torch.Size([4, 2, 16]), f\"Wrong outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Encoder_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c59d3e8bf698511a855df8b7fbc04491",
     "grade": false,
     "grade_id": "cell-102038af7faba64b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aea4e7f9885ee84d12e6ab183ffa4c45",
     "grade": false,
     "grade_id": "cell-3133e50590987e56",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Subsequent mask\n",
    "\n",
    "In the training loop, we will use target sequences (starting with `SOS_token`) as inputs of the decoder. By doing that, we make it possible for the decoder to use previously decoded words when predicting probabilities of the next word. This idea is similar to the way decoding was done in Exercise 5. However, the computations are parallelized in the transformer decoder, and the probabilities of each word in the target sequence are produced by doing one pass through the decoder.\n",
    "\n",
    "During decoding, we need to make sure that when we compute the probability of the next word, we only use preceding and not subsequent words. In transformers, this is done by providing a mask which tells which elements should be used or ignored when producing the output. The following function produces this kind of mask.\n",
    "\n",
    "The $i$-th row in the produced mask says which of the input elements should be used to compute the $i$-th element of the output:\n",
    "* `0`: the corresponding element of the input sequence can be used.\n",
    "* `-inf`: the corresponding element of the input sequence cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c91dbc90b6c803baeffb280bbf39324b",
     "grade": false,
     "grade_id": "cell-c2dfee9a9f2d674e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20d6d1ff1df0c0609a1cfc1954e4e94c",
     "grade": false,
     "grade_id": "cell-ec36a7f1884b54f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7f254da9b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a typical mask that we need to use while decoding\n",
    "mask = subsequent_mask(10)\n",
    "print(mask)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fd616d35ce77265afe2da3e1f6ec21d",
     "grade": false,
     "grade_id": "cell-c26c4a8fecf141bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"decoder_block.png\" width=150 style=\"float: right;\">\n",
    "\n",
    "## Decoder block\n",
    "\n",
    "Next we implement one block of the transformer decoder (see the figure on the right).\n",
    "* We recommend you to use layers available in PyTorch:\n",
    "  * [nn.LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) to implement the `Norm` layer in the figure\n",
    "  * [nn.Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) to implement dropout\n",
    "  * [nn.MultiheadAttention](https://pytorch.org/docs/stable/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention) to implement `Multi-Head Attention`.\n",
    "\n",
    "* `Feedforward` is simply an MLP processing each position (each element of the source sequence) independently. The exact implementation of the MLP is not tested in this notebook. We used an MLP with:\n",
    "  * one hidden layer with `n_hidden` neurons\n",
    "  * a dropout and ReLU activation after the hidden layer\n",
    "  * an output layer with `n_features` outputs.\n",
    "\n",
    "* We used dropout in both skip connections, similarly to the Annotated transformer.\n",
    "\n",
    "Notes:\n",
    "* The first attention block is self-attention when query, key and value inputs are same. The second attention block uses the encoded `z` values as keys and values, and the outputs of the previous layer as query.\n",
    "* **We recommend you to test that the subsequent values of the input sequence do not affect the outputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb67fd2eeaa7f39da46db1eac279cd90",
     "grade": false,
     "grade_id": "DecoderBlock",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_features: Number of input and output features.\n",
    "          n_heads: Number of attention heads in the Multi-Head Attention.\n",
    "          n_hidden: Number of hidden units in the Feedforward (MLP) block.\n",
    "          dropout: Dropout rate after the first layer of the MLP and the two skip connections.\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.multiheadAttention1 = nn.MultiheadAttention(n_features, n_heads)\n",
    "        self.multiheadAttention2 = nn.MultiheadAttention(n_features, n_heads)\n",
    "        self.normlayer1 = nn.LayerNorm(n_features)\n",
    "        self.normlayer2 = nn.LayerNorm(n_features)\n",
    "        self.normlayer3 = nn.LayerNorm(n_features)\n",
    "        self.mlp1 = nn.Sequential(nn.Linear(n_features, n_hidden), nn.Dropout(dropout),\n",
    "                                    nn.ReLU(), torch.nn.Linear(n_hidden,n_features))\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, y, z, src_mask, tgt_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y of shape (max_tgt_seq_length, batch_size, n_features): Transformed target sequences used as the inputs\n",
    "              of the block.\n",
    "          z of shape (max_src_seq_length, batch_size, n_features): Encoded source sequences (outputs of the\n",
    "              encoder).\n",
    "          src_mask of shape (batch_size, max_src_seq_length): Boolean tensor indicating which elements of the\n",
    "             source sequences should be ignored.\n",
    "          tgt_mask of shape (max_tgt_seq_length, max_tgt_seq_length): Subsequent mask to ignore subsequent\n",
    "             elements of the target sequences in the inputs. The rows of this matrix correspond to the output\n",
    "             elements and the columns correspond to the input elements.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Output tensor.\n",
    "\n",
    "        Note: All intermediate signals should be of shape (max_seq_length, batch_size, n_features).\n",
    "        \"\"\"\n",
    "        x, _ = self.multiheadAttention1(query=y, key=y, value=y, attn_mask =tgt_mask)\n",
    "        x = self.normlayer1(self.drop1(x) + y)\n",
    "        y, _ = self.multiheadAttention2(query=x, key=z, value=z, key_padding_mask=src_mask)\n",
    "        x = self.normlayer2(self.drop2(y) + x)\n",
    "        x = self.normlayer3(x + self.drop3(self.mlp1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2678a63f80355e0a72b488a6f05bc0f2",
     "grade": false,
     "grade_id": "cell-586469eac0b19254",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_DecoderBlock_shapes():\n",
    "    decoder_block = DecoderBlock(n_features=16, n_heads=4, n_hidden=64)\n",
    "\n",
    "    y = torch.tensor([\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 0],\n",
    "        [6, 0],\n",
    "    ]).float().view(4, 2, 1).repeat(1, 1, 16)  # (max_seq_length, batch_size, n_features)\n",
    "\n",
    "    z = torch.randn(4, 2, 16, requires_grad=True)  # (max_seq_length, batch_size, n_features)\n",
    "\n",
    "    src_mask = torch.tensor([\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "    ], dtype=torch.bool).T  # (batch_size, max_seq_length)\n",
    "\n",
    "    tgt_mask = subsequent_mask(y.size(0))\n",
    "\n",
    "    outputs = decoder_block(y, z, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "    assert outputs.shape == torch.Size([4, 2, 16]), f\"Wrong outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_DecoderBlock_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd5a1efcc88dc360d0259d3387b9a826",
     "grade": true,
     "grade_id": "test_DecoderBlock",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests DecoderBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4af57790480337233da05440de8d44c",
     "grade": false,
     "grade_id": "cell-a30448f3b22189c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"decoder.png\" width=200 style=\"float: right;\">\n",
    "\n",
    "## Decoder\n",
    "\n",
    "The decoder is a stack of the following blocks:\n",
    "* Embedding of words (please use [nn.Embedding](https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding))\n",
    "* Positional encoding (please use `tr.PositionalEncoding` from the attached module)\n",
    "* `n_blocks` of the `DecoderBlock` modules.\n",
    "* A linear layer with `tgt_vocab_size` output features.\n",
    "* Log_softmax nonlinearity.\n",
    "\n",
    "Note: our longest sequences have length `MAX_LENGTH`, this is the value that you can use when you specify `PositionalEncoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6efd14344c03f561efb63e5c0fa6fb5e",
     "grade": false,
     "grade_id": "Decoder",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tgt_vocab_size, n_blocks, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          tgt_vocab_size: Number of words in the target vocabulary.\n",
    "          n_blocks: Number of EncoderBlock blocks.\n",
    "          n_features: Number of features to be used for word embedding and further in all layers of the decoder.\n",
    "          n_heads: Number of attention heads inside the DecoderBlock.\n",
    "          n_hidden: Number of hidden units in the Feedforward block of DecoderBlock.\n",
    "          dropout: Dropout level used in DecoderBlock.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed1 = nn.Embedding(tgt_vocab_size, n_features)\n",
    "        self.pos_embed = tr.PositionalEncoding(n_features, max_len=MAX_LENGTH+1)\n",
    "        self.dencoder_blks = nn.Sequential(*[DecoderBlock(n_features, n_heads, n_hidden, dropout) for _ in range(n_blocks)])\n",
    "        self.linear_layer = nn.Linear(n_features,tgt_vocab_size)\n",
    "        \n",
    "    def forward(self, y, z, src_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y of shape (max_tgt_seq_length, batch_size, n_features): Transformed target sequences used as the inputs\n",
    "              of the block.\n",
    "          z of shape (max_src_seq_length, batch_size, n_features): Encoded source sequences (outputs of the\n",
    "              encoder).\n",
    "          src_mask of shape (batch_size, max_src_seq_length): Boolean tensor indicating which elements of the\n",
    "             source sequences should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (max_seq_length, batch_size, tgt_vocab_size): Log-softmax probabilities of the words\n",
    "              in the output sequences.\n",
    "\n",
    "        Notes:\n",
    "          * All intermediate signals should be of shape (max_seq_length, batch_size, n_features).\n",
    "          * You need to create and use the subsequent mask in the decoder.\n",
    "        \"\"\"\n",
    "        emb = self.embed1(y)\n",
    "        pos = self.pos_embed(emb)\n",
    "        inp = emb + pos \n",
    "        tgt_masks = subsequent_mask(y.size(0))\n",
    "        for i,layer in enumerate(self.dencoder_blks):\n",
    "            #tgt_masks[i,:] = 0\n",
    "            inp = layer(inp,z,src_mask,tgt_masks)\n",
    "        x = F.log_softmax(self.linear_layer(inp), dim=2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b44650a21d18010aafeff62ecb83d9c5",
     "grade": false,
     "grade_id": "cell-2511aa618604b4a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Decoder_shapes():\n",
    "    decoder = Decoder(tgt_vocab_size=10, n_blocks=1, n_features=16, n_heads=4, n_hidden=64)\n",
    "\n",
    "    y = torch.tensor([\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 0],\n",
    "        [6, 0],\n",
    "    ])  # (max_seq_length, batch_size, n_features)\n",
    "\n",
    "    z = torch.randn(4, 2, 16)  # (max_seq_length, batch_size, n_features)\n",
    "\n",
    "    src_mask = torch.tensor([\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "    ], dtype=torch.bool).T  # (batch_size, max_seq_length)\n",
    "\n",
    "    outputs = decoder(y, z, src_mask=src_mask)\n",
    "    assert outputs.shape == torch.Size([4, 2, 10]), f\"Wrong outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Decoder_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac142e2969764fa1e646091bf0255a7a",
     "grade": false,
     "grade_id": "cell-10c28584fb58b386",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21ab3ba0364f3ec7e43d3204c702e831",
     "grade": false,
     "grade_id": "cell-ec608760ebfa7f8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embed1): Embedding(2925, 256)\n",
       "  (pos_embed): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dencoder_blks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (multiheadAttention1): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (multiheadAttention2): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (normlayer1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (drop3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (multiheadAttention1): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (multiheadAttention2): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (normlayer1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (drop3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (multiheadAttention1): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (multiheadAttention2): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (normlayer1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (normlayer3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (drop3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer): Linear(in_features=256, out_features=2925, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the transformer model\n",
    "n_features = 256\n",
    "encoder = Encoder(src_vocab_size=trainset.input_lang.n_words, n_blocks=3, n_features=n_features,\n",
    "                  n_heads=16, n_hidden=1024)\n",
    "decoder = Decoder(tgt_vocab_size=trainset.output_lang.n_words, n_blocks=3, n_features=n_features,\n",
    "                  n_heads=16, n_hidden=1024)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7797d6c950c67652f64789f70d9a050",
     "grade": false,
     "grade_id": "cell-b1645c0797a9d5f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "In the training loop, we first encode source sequences using the encoder. Then we decode the encoded sequences by the decoder which also receives shifted target sequences as inputs. The decoder outputs a tensor that contains log-softmax probabilities of words in the output language. You need to use those probabilities to compute the loss. Note that you need to ignore the padded values in the target sequences (similarly to Exercise 5).\n",
    "\n",
    "The training loss should be smaller than 0.23 at the end of training. 40 epochs is typically enough to get to that level.\n",
    "\n",
    "**Important: Use the `NoamOptimizer` defined below. If you use standard optimizers like Adam, the optimization procedure will most likely fail.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5e9e6a3f67af78c11dd7b4785d80731",
     "grade": false,
     "grade_id": "cell-3dcb8dddc9bd9ee7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "adam = torch.optim.Adam(parameters, lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "optimizer = tr.NoamOptimizer(n_features, 2, 10000, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "324942900c9447302b13235d20ba48ec",
     "grade": false,
     "grade_id": "cell-8a12754e13e91bef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    %matplotlib inline\n",
    "    import time\n",
    "    import pylab as pl\n",
    "    from IPython import display\n",
    "    \n",
    "    def live_plot(data):\n",
    "        pl.plot(data)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "    loss_values = []\n",
    "    batch_size=64\n",
    "    criteria = nn.NLLLoss(ignore_index=PADDING_VALUE)\n",
    "    for i in range(40):\n",
    "        for j,(sentence_batches, seq_masks, targets)  in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            x = encoder.forward(sentence_batches, seq_masks.T)\n",
    "            dec_out = decoder.forward(targets[:-1], x, seq_masks.T)\n",
    "            loss = criteria(dec_out.permute((1,2,0)), torch.transpose(targets[1:],0,1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_values.append(loss.item())\n",
    "        live_plot(loss_values)\n",
    "        print('Epoch: %d. Training loss: %f' % (i+1, loss.item()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08580f112f8d4db725e98728207e7e26",
     "grade": false,
     "grade_id": "accuracy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 6_tr_encoder.pth.\n",
      "Model loaded from 6_tr_decoder.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    tools.save_model(encoder, '6_tr_encoder.pth')\n",
    "    tools.save_model(decoder, '6_tr_decoder.pth')\n",
    "else:\n",
    "    encoder = Encoder(src_vocab_size=trainset.input_lang.n_words, n_blocks=3, n_features=256, n_heads=16, n_hidden=1024)\n",
    "    tools.load_model(encoder, '6_tr_encoder.pth', device)\n",
    "    \n",
    "    decoder = Decoder(tgt_vocab_size=trainset.output_lang.n_words, n_blocks=3, n_features=256, n_heads=16, n_hidden=1024)\n",
    "    tools.load_model(decoder, '6_tr_decoder.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54788aadd640f3e28e828ecd8bac433a",
     "grade": true,
     "grade_id": "cell-985f2404fb056035",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the trained transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e17b377e3dc43691624258b933fbbcee",
     "grade": false,
     "grade_id": "cell-25e4072e5588afaa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Generate translations with the trained model\n",
    "\n",
    "In the cell below, implement a function that converts an input sequence to an output sequence using the trained transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98d0db2a273b0d26f3464d1e1e640d11",
     "grade": false,
     "grade_id": "cell-2122447b9917f9b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, src_seq):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      encoder (Encoder): Trained encoder.\n",
    "      decoder (Decoder): Trained decoder.\n",
    "      src_seq of shape (src_seq_length): LongTensor of word indices of the source sentence.\n",
    "    \n",
    "    Returns:\n",
    "      out_seq of shape (out_seq_length, 1): LongTensor of word indices of the output sentence.\n",
    "    \"\"\"\n",
    "    seq_mask = torch.zeros_like(src_seq, dtype=torch.bool)\n",
    "    x = encoder.forward(src_seq.unsqueeze(0), seq_mask.unsqueeze(1))\n",
    "    tgt_sub = [SOS_token,]\n",
    "    i=0\n",
    "    while True:\n",
    "        dec_out = decoder.forward(torch.tensor(tgt_sub, device=device).unsqueeze(1), x, seq_mask.unsqueeze(1).T)\n",
    "        dec_out = torch.argmax(dec_out, dim=2)\n",
    "        tgt_sub.append(dec_out[i])\n",
    "        if dec_out[i] == EOS_token :\n",
    "            break\n",
    "        i+=1\n",
    "    return dec_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccd8f4bdf1f0deb26e2d19f063153ae9",
     "grade": false,
     "grade_id": "cell-22b623f5d5351a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below, we translate sentences from the training set. For a well-trained transformer, the translations should look similar to the target sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b9887d55695ce56e65b6d850af37578",
     "grade": false,
     "grade_id": "cell-9fba1fede2232e76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate training data:\n",
      "-----------------------------\n",
      "> je suis moi meme un peu lecteur . EOS\n",
      "= i m a bit of a reader myself . EOS\n",
      "< i m a bit of a reader myself . EOS \n",
      "\n",
      "> je suis en train d apprendre le francais . EOS\n",
      "= i m learning french . EOS\n",
      "< i m managing it . EOS \n",
      "\n",
      "> nous sommes tous en securite . EOS\n",
      "= we re all safe . EOS\n",
      "< we re all done . EOS \n",
      "\n",
      "> elle est en colere contre moi . EOS\n",
      "= she is mad at me . EOS\n",
      "< she is mad at me . EOS \n",
      "\n",
      "> je suis tout seul . EOS\n",
      "= i m all alone . EOS\n",
      "< i m very hungry . EOS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate training data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    src_sentence, tgt_sentence = trainset[np.random.choice(len(trainset))]\n",
    "    print('>', ' '.join(trainset.input_lang.index2word[i.item()] for i in src_sentence))\n",
    "    print('=', ' '.join(trainset.output_lang.index2word[i.item()] for i in tgt_sentence))\n",
    "    out_sentence = translate(encoder, decoder, src_sentence)\n",
    "    print('<', ' '.join(trainset.output_lang.index2word[i.item()] for i in out_sentence), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd0798d4f5e481ff8449925b3c934ea7",
     "grade": false,
     "grade_id": "cell-a8c5476c494b3dea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below, we translate sentences from the test set. For a well-trained transformer, the translations are typically\n",
    "worse than for the training sequences but they still look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f268ad9539d79bc2af8e349a2a94ff99",
     "grade": false,
     "grade_id": "cell-e27f5e4329673f0d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "testset = TranslationDataset(data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df287dda075179fd01021a51c75a1607",
     "grade": false,
     "grade_id": "cell-c1cafaf3ca027d6d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate test data:\n",
      "-----------------------------\n",
      "> je ne vais pas attendre . EOS\n",
      "= i m not going to wait . EOS\n",
      "< i m not waiting for it . EOS \n",
      "\n",
      "> vous etes tellement idiote ! EOS\n",
      "= you are so stupid . EOS\n",
      "< you re so predictable . EOS \n",
      "\n",
      "> c est toi qui t es emballe . EOS\n",
      "= you re the one that went crazy . EOS\n",
      "< you re kind of mine . EOS \n",
      "\n",
      "> vous etes tres occupes . EOS\n",
      "= you re very busy . EOS\n",
      "< you re very busy . EOS \n",
      "\n",
      "> je vais rentrer a la maison demain . EOS\n",
      "= i m going back home tomorrow . EOS\n",
      "< i m going to the house . EOS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate test data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    input_sentence, target_sentence = testset[np.random.choice(len(testset))]\n",
    "    print('>', ' '.join(testset.input_lang.index2word[i.item()] for i in input_sentence))\n",
    "    print('=', ' '.join(testset.output_lang.index2word[i.item()] for i in target_sentence))\n",
    "    output_sentence = translate(encoder, decoder, input_sentence)\n",
    "    print('<', ' '.join(testset.output_lang.index2word[i.item()] for i in output_sentence), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
